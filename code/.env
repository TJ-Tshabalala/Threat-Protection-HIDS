--- Ollama Configuration ---
The URL where the local Ollama server is running.
The default http://localhost:11434
OLLAMA_URL = http://localhost:11434/api/generate

# The LLM model in use = llama3
